{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ce3da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.metrics.wer import word_error_rate\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a7b795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-09-06 09:15:58 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/QuartzNet15x5Base-En.nemo to /home/ubuntu/.cache/torch/NeMo/NeMo_1.3.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2021-09-06 09:16:00 common:681] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-09-06 09:16:01 features:252] PADDING: 16\n",
      "[NeMo I 2021-09-06 09:16:01 features:269] STFT using torch\n",
      "[NeMo I 2021-09-06 09:16:06 save_restore_connector:143] Model EncDecCTCModel was successfully restored from /home/ubuntu/.cache/torch/NeMo/NeMo_1.3.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
     ]
    }
   ],
   "source": [
    "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79465934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-09-06 09:16:06 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small_ls/versions/1.0.0/files/stt_en_conformer_ctc_small_ls.nemo to /home/ubuntu/.cache/torch/NeMo/NeMo_1.3.0/stt_en_conformer_ctc_small_ls/cf1b6bbcc08433257c12442c92b9996a/stt_en_conformer_ctc_small_ls.nemo\n",
      "[NeMo I 2021-09-06 09:16:07 common:681] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-09-06 09:16:08 mixins:147] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-09-06 09:16:08 modelPT:130] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/Librispeech_SP_Tarred/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/Librispeech_SP_Tarred/audio__OP_0..511_CL_.tar\n",
      "    \n",
      "[NeMo W 2021-09-06 09:16:08 modelPT:137] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: /data/LibriSpeech/eval__OP_0..1023_CL_.tar\n",
      "    \n",
      "[NeMo W 2021-09-06 09:16:08 modelPT:143] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: /data/LibriSpeech/eval__OP_0..1023_CL_.tar\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-09-06 09:16:08 features:252] PADDING: 0\n",
      "[NeMo I 2021-09-06 09:16:08 features:269] STFT using torch\n",
      "[NeMo I 2021-09-06 09:16:08 save_restore_connector:143] Model EncDecCTCModelBPE was successfully restored from /home/ubuntu/.cache/torch/NeMo/NeMo_1.3.0/stt_en_conformer_ctc_small_ls/cf1b6bbcc08433257c12442c92b9996a/stt_en_conformer_ctc_small_ls.nemo.\n"
     ]
    }
   ],
   "source": [
    "asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(model_name=\"stt_en_conformer_ctc_small_ls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "558bcf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading manifest data: 1224863it [00:05, 219285.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# download s3://model-data-platform/validated/  for manifest and wav files\n",
    "def read_manifest(path):\n",
    "    manifest = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in tqdm.tqdm(f, desc=\"Reading manifest data\"):\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            data = json.loads(line)\n",
    "            manifest.append(data)\n",
    "    return manifest\n",
    "# train_manifest_path = '/Users/dami.osoba/work/bawk/src/data/commonvoice_train_manifest.json'\n",
    "train_manifest_path = \"../../commonvoice_validated_manifest.json\"\n",
    "train_manifest_data = read_manifest(train_manifest_path)\n",
    "train_path = [(data['audio_filepath'].replace('validated','wav_clips'), data['text']) for data in train_manifest_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b9024f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [a[0] for a in train_path[:100]]\n",
    "transcription = [a[1] for a in train_path[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cbf83fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5bd7cd98a147aa9e746f7a14f0cfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get transcriptions \n",
    "hypothesis = asr_model.transcribe(paths2audio_files=files[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c77e22eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['six o',\n",
       " 'all is well that ends well',\n",
       " 'loyal in me',\n",
       " 'the new patch is less invasing than the ole one but still causes redrection',\n",
       " 'how is monsieur a going to bandle and be with is a due and cue']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9940f613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['six',\n",
       " \"all's well that ends well.\",\n",
       " 'do you mean it?',\n",
       " 'the new patch is less invasive than the old one, but still causes regressions.',\n",
       " 'how is mozilla going to handle ambiguities like queue and cue?']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actual\n",
    "transcription[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb4ab081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5379388448471121\n"
     ]
    }
   ],
   "source": [
    "#get word error rate\n",
    "wer = word_error_rate(hypotheses=hypothesis, references=transcription)\n",
    "print(wer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ex)",
   "language": "python",
   "name": "ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
