{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce3da0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-09-09 16:24:03 optimizers:47] Apex was not found. Using the lamb optimizer will error out.\n",
      "[NeMo W 2021-09-09 16:24:07 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text_dali.AudioToCharDALIDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.metrics.wer import word_error_rate\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d179866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_256,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_256,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_256/versions/1.0.0rc1/files/stt_en_citrinet_256.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_512,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_512,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512/versions/1.0.0rc1/files/stt_en_citrinet_512.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_1024,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024/versions/1.0.0rc1/files/stt_en_citrinet_1024.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_256_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_256_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_256_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_256_gamma_0_25.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_512_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_512_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_512_gamma_0_25.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_1024_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_1024_gamma_0_25.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_es_citrinet_512,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_citrinet_512,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_citrinet_512/versions/1.0.0/files/stt_es_citrinet_512.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_small,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_small,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small/versions/1.0.0/files/stt_en_conformer_ctc_small.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_medium,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_medium,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_medium/versions/1.0.0/files/stt_en_conformer_ctc_medium.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_large/versions/1.0.0/files/stt_en_conformer_ctc_large.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_small_ls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_small_ls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small_ls/versions/1.0.0/files/stt_en_conformer_ctc_small_ls.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_medium_ls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_medium_ls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_medium_ls/versions/1.0.0/files/stt_en_conformer_ctc_medium_ls.nemo\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_large_ls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_large_ls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_large_ls/versions/1.0.0/files/stt_en_conformer_ctc_large_ls.nemo\n",
       " )]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nemo_asr.models.EncDecCTCModelBPE.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a7b795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-09-09 16:26:37 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/QuartzNet15x5Base-En.nemo to /Users/dami.osoba/.cache/torch/NeMo/NeMo_1.2.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2021-09-09 16:27:15 common:676] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-09-09 16:27:16 features:252] PADDING: 16\n",
      "[NeMo I 2021-09-09 16:27:16 features:269] STFT using torch\n",
      "[NeMo I 2021-09-09 16:27:16 modelPT:438] Model EncDecCTCModel was successfully restored from /Users/dami.osoba/.cache/torch/NeMo/NeMo_1.2.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
     ]
    }
   ],
   "source": [
    "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79465934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-09-06 09:16:06 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small_ls/versions/1.0.0/files/stt_en_conformer_ctc_small_ls.nemo to /home/ubuntu/.cache/torch/NeMo/NeMo_1.3.0/stt_en_conformer_ctc_small_ls/cf1b6bbcc08433257c12442c92b9996a/stt_en_conformer_ctc_small_ls.nemo\n",
      "[NeMo I 2021-09-06 09:16:07 common:681] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-09-06 09:16:08 mixins:147] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-09-06 09:16:08 modelPT:130] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/Librispeech_SP_Tarred/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/Librispeech_SP_Tarred/audio__OP_0..511_CL_.tar\n",
      "    \n",
      "[NeMo W 2021-09-06 09:16:08 modelPT:137] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: /data/LibriSpeech/eval__OP_0..1023_CL_.tar\n",
      "    \n",
      "[NeMo W 2021-09-06 09:16:08 modelPT:143] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: /data/LibriSpeech/eval__OP_0..1023_CL_.tar\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-09-06 09:16:08 features:252] PADDING: 0\n",
      "[NeMo I 2021-09-06 09:16:08 features:269] STFT using torch\n",
      "[NeMo I 2021-09-06 09:16:08 save_restore_connector:143] Model EncDecCTCModelBPE was successfully restored from /home/ubuntu/.cache/torch/NeMo/NeMo_1.3.0/stt_en_conformer_ctc_small_ls/cf1b6bbcc08433257c12442c92b9996a/stt_en_conformer_ctc_small_ls.nemo.\n"
     ]
    }
   ],
   "source": [
    "asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(model_name=\"stt_en_conformer_ctc_small_ls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558bcf0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../commonvoice_validated_manifest.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-efb59fe85b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# train_manifest_path = '/Users/dami.osoba/work/bawk/src/data/commonvoice_train_manifest.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_manifest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../commonvoice_validated_manifest.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_manifest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_manifest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_manifest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_filepath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wav_clips'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_manifest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-efb59fe85b14>\u001b[0m in \u001b[0;36mread_manifest\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_manifest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmanifest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Reading manifest data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../commonvoice_validated_manifest.json'"
     ]
    }
   ],
   "source": [
    "# download s3://model-data-platform/validated/  for manifest and wav files\n",
    "def read_manifest(path):\n",
    "    manifest = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in tqdm.tqdm(f, desc=\"Reading manifest data\"):\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            data = json.loads(line)\n",
    "            manifest.append(data)\n",
    "    return manifest\n",
    "# train_manifest_path = '/Users/dami.osoba/work/bawk/src/data/commonvoice_train_manifest.json'\n",
    "train_manifest_path = \"../../commonvoice_validated_manifest.json\"\n",
    "train_manifest_data = read_manifest(train_manifest_path)\n",
    "train_path = [(data['audio_filepath'].replace('validated','wav_clips'), data['text']) for data in train_manifest_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b9024f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [a[0] for a in train_path[:100]]\n",
    "transcription = [a[1] for a in train_path[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cbf83fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5bd7cd98a147aa9e746f7a14f0cfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get transcriptions \n",
    "hypothesis = asr_model.transcribe(paths2audio_files=files[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c77e22eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['six o',\n",
       " 'all is well that ends well',\n",
       " 'loyal in me',\n",
       " 'the new patch is less invasing than the ole one but still causes redrection',\n",
       " 'how is monsieur a going to bandle and be with is a due and cue']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9940f613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['six',\n",
       " \"all's well that ends well.\",\n",
       " 'do you mean it?',\n",
       " 'the new patch is less invasive than the old one, but still causes regressions.',\n",
       " 'how is mozilla going to handle ambiguities like queue and cue?']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actual\n",
    "transcription[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb4ab081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5379388448471121\n"
     ]
    }
   ],
   "source": [
    "#get word error rate\n",
    "wer = word_error_rate(hypotheses=hypothesis, references=transcription)\n",
    "print(wer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
